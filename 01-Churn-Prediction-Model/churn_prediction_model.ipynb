{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40b7ade",
   "metadata": {},
   "source": [
    "# Project: Predictive Churn Model\n",
    "\n",
    "**Business Objective:** To build a machine learning model capable of predicting which customers are most likely to churn, enabling proactive retention strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33198e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Essential Libraries ---\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Ignores warnings for a cleaner output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0be167",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation\n",
    "First, we load the data and perform a simple pre-processing to make it ready for the model. We'll convert categorical 'Yes'/'No' columns to numbers (1/0) and select a few relevant features to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2ef96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# --- Data Treatment ---\n",
    "# Convert the target column 'Churn' to a binary format (0 for 'No', 1 for 'Yes')\n",
    "df['Churn_numeric'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# The 'TotalCharges' column can have spaces and should be numeric.\n",
    "# The 'coerce' option will turn any problematic values into NaN (Not a Number).\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Drop any rows that now have NaN values to ensure data quality.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define our features (X) and our target (y)\n",
    "# For this first model, we'll use simple numerical features.\n",
    "X = df[['tenure', 'MonthlyCharges', 'TotalCharges']]  # The characteristics the model will use to predict\n",
    "y = df['Churn_numeric']                               # The answer we want the model to learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1118eb7e",
   "metadata": {},
   "source": [
    "## Step 2: Train-Test Split\n",
    "This is a critical step to ensure an unbiased evaluation of our model. We split our data into a training set (80%) and a testing set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b16dd781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5625 samples\n",
      "Test set size: 1407 samples\n"
     ]
    }
   ],
   "source": [
    "# random_state=42 ensures that our split is the same every time we run the code, for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a798fa7",
   "metadata": {},
   "source": [
    "## Step 3 & 4: Model Training and Prediction\n",
    "We will use a Logistic Regression model, a great starting point for classification problems. We'll train it on the training data and then use it to make predictions on the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b02d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initialize and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions on the test set\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86eab3",
   "metadata": {},
   "source": [
    "## Step 5: Model Evaluation\n",
    "Now we compare the model's `predictions` with the actual `y_test` values to see how well it performed. We'll look at Accuracy and the Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da0d64f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 77.97%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Did Not Churn       0.81      0.91      0.86      1033\n",
      "      Churned       0.62      0.43      0.51       374\n",
      "\n",
      "     accuracy                           0.78      1407\n",
      "    macro avg       0.72      0.67      0.68      1407\n",
      " weighted avg       0.76      0.78      0.76      1407\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[937  96]\n",
      " [214 160]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the overall accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print the Classification Report for a detailed view of precision, recall, and f1-score\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions, target_names=['Did Not Churn', 'Churned']))\n",
    "\n",
    "# Print the Confusion Matrix for a clear view of the model's errors\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "# [[True Negatives, False Positives],\n",
    "#  [False Negatives,   True Positives]]\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c800ed8",
   "metadata": {},
   "source": [
    "## Final Insights & Business Interpretation\n",
    "\n",
    "The initial model achieved an **accuracy of approximately 78%**, which is a good starting point, significantly better than random guessing. However, a deeper look into the classification report and confusion matrix reveals a critical nuance:\n",
    "\n",
    "* **Strength:** The model is very effective at correctly identifying customers who **will not churn** (a recall of 0.91 for the 'Did Not Churn' class). This means it generates few \"false alarms\" for happy customers.\n",
    "\n",
    "* **Critical Weakness:** The model's primary weakness is its low **recall of 0.43 for the 'Churned' class**. This means that out of all the customers who actually did churn, our model only managed to identify 43% of them. The `214` **False Negatives** in the confusion matrix represent **214 lost opportunities for retention**â€”the most expensive error for the business.\n",
    "\n",
    "**Conclusion:** This is a solid **baseline model**, but it is too \"conservative\" for a real-world business application. The next steps would be to focus on improving the model's recall, even if it means slightly lowering precision. We need a model that is better at \"sounding the alarm\" for at-risk customers, as the cost of a false alarm is much lower than the cost of losing a customer we failed to identify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dados",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
